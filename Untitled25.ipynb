{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae89992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv('hate_speech.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe332fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87917e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3000\n",
       "1    2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363bc269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -  â #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex\n",
      "2 - we are so selfish. #orlando #standwithorlando #pulseshooting #orlandoshooting #biggerproblems #selfish #heabreaking   #values #love #\n",
      "3 - i get to see my daddy today!!   #80days #gettingfed\n",
      "4 - ouch...junior is angryð#got7 #junior #yugyoem   #omg \n",
      "5 - i am thankful for having a paner. #thankful #positive     \n"
     ]
    }
   ],
   "source": [
    "for index,tweet in enumerate(dataset[\"tweet\"][10:15]):\n",
    "    print(index+1,\"-\",tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9181519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text=re.sub(r'[^a-zA-Z\\']', ' ', text)\n",
    "    text=re.sub(r'[^\\x00-\\x7F]+', ' ',text)\n",
    "    text=text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21df0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_text']=dataset.tweet.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3951e1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user  user thanks for  lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>user camping tomorrow  user  user  user  use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>the next school year is the year for exams    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>we won    love the land     allin  cavs  champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>user  user welcome here    i'm   it's so  gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7   8      0  the next school year is the year for exams.ð...   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "\n",
       "                                          clean_text  \n",
       "0    user when a father is dysfunctional and is s...  \n",
       "1   user  user thanks for  lyft credit i can't us...  \n",
       "2                                bihday your majesty  \n",
       "3   model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now     motivation  \n",
       "5        huge fan fare and big talking before the...  \n",
       "6    user camping tomorrow  user  user  user  use...  \n",
       "7  the next school year is the year for exams    ...  \n",
       "8  we won    love the land     allin  cavs  champ...  \n",
       "9    user  user welcome here    i'm   it's so  gr...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f314f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b880d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56062ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799f7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_freq(text):\n",
    "    word_list=[]\n",
    "    for tw_words in text.split():\n",
    "        word_list.extend(tw_words)\n",
    "    word_freq=pd.Series(word_list).value_counts()\n",
    "    word_freq=word_freq.drop(stop, errors='ignore')\n",
    "    return word_freq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fea1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_neg(words):\n",
    "    for word in words:\n",
    "        if word in['n', 'no', 'non', 'not'] or re.search(r\"\\wn't\", word):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d3a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_rare(words, rare_100):\n",
    "    for word in words:\n",
    "        if word in rare_100:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e7a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(words):\n",
    "    for word in words:\n",
    "        if word in['when','what','how','why','who','where']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c1f4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = gen_freq(dataset.clean_text.str)  \n",
    "rare_100 = word_freq[-100:]  \n",
    "dataset['word_count'] = dataset.clean_text.str.split().apply(lambda x: len(x))  \n",
    "dataset['any_neg'] = dataset.clean_text.str.split().apply(lambda x: any_neg(x)) \n",
    "dataset['is_question'] = dataset.clean_text.str.split().apply(lambda x: is_question(x))  \n",
    "dataset['any_rare'] = dataset.clean_text.str.split().apply(lambda x: any_rare(x, rare_100))  \n",
    "dataset['char_count'] = dataset.clean_text.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23aedff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=dataset[['word_count', 'any_neg', 'any_rare', 'char_count', 'is_question']]\n",
    "y=dataset.label\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "560ebe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "model=model.fit(X_train,y_train)\n",
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bc13adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0da923f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (from scikit-learn) (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25877e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (1.2.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     ---------------------------------------- 11.1/11.1 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.1\n",
      "    Uninstalling scikit-learn-1.2.1:\n",
      "      Successfully uninstalled scikit-learn-1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\sindh\\\\OneDrive\\\\Documents\\\\anaconda\\\\Lib\\\\site-packages\\\\~klearn\\\\datasets\\\\_svmlight_format_fast.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sindh\\onedrive\\documents\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d726c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.99332697807436 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f4021fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf=RandomForestClassifier()\n",
    "clf_rf.fit(X_train,y_train)\n",
    "rf_pred=clf_rf.predict(X_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d44ac0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[408 191]\n",
      " [236 214]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66       599\n",
      "           1       0.53      0.48      0.50       450\n",
      "\n",
      "    accuracy                           0.59      1049\n",
      "   macro avg       0.58      0.58      0.58      1049\n",
      "weighted avg       0.59      0.59      0.59      1049\n",
      "\n",
      "Accuracy: 0.5929456625357483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,rf_pred))\n",
    "print(classification_report(y_test,rf_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29ad1b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.61       599\n",
      "           1       0.49      0.54      0.52       450\n",
      "\n",
      "    accuracy                           0.57      1049\n",
      "   macro avg       0.56      0.56      0.56      1049\n",
      "weighted avg       0.57      0.57      0.57      1049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "logreg = LogisticRegression (class_weight='balanced') \n",
    "logreg.fit(X_train, y_train) \n",
    "y_pred = logreg.predict(X_test) #predicting the values \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c9c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
